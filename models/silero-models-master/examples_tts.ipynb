{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "previous-bacon",
   "metadata": {
    "id": "previous-bacon"
   },
   "source": [
    "# Dependencies and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-receiver",
   "metadata": {
    "cellView": "form",
    "id": "complicated-receiver"
   },
   "outputs": [],
   "source": [
    "#@title Install dependencies\n",
    "\n",
    "!pip install -q torchaudio omegaconf\n",
    "\n",
    "import torch\n",
    "from pprint import pprint\n",
    "from omegaconf import OmegaConf\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "torch.hub.download_url_to_file('https://raw.githubusercontent.com/snakers4/silero-models/master/models.yml',\n",
    "                               'latest_silero_models.yml',\n",
    "                               progress=False)\n",
    "models = OmegaConf.load('latest_silero_models.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-intention",
   "metadata": {
    "id": "nasty-intention"
   },
   "source": [
    "# Colab Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-injury",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T06:44:34.516921Z",
     "start_time": "2021-03-29T06:44:34.510879Z"
    },
    "id": "pacific-injury"
   },
   "outputs": [],
   "source": [
    "# see latest avaiable models\n",
    "available_languages = list(models.tts_models.keys())\n",
    "print(f'Available languages {available_languages}')\n",
    "\n",
    "for lang in available_languages:\n",
    "    speakers = list(models.tts_models.get(lang).keys())\n",
    "    print(f'Available speakers for {lang}: {speakers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-naples",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T06:46:39.993648Z",
     "start_time": "2021-03-29T06:46:39.052349Z"
    },
    "id": "stupid-naples"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "language = 'ru'\n",
    "speaker = 'kseniya_16khz'\n",
    "device = torch.device('cpu')\n",
    "model, symbols, sample_rate, example_text, apply_tts = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
    "                                                                      model='silero_tts',\n",
    "                                                                      language=language,\n",
    "                                                                      speaker=speaker)\n",
    "model = model.to(device)  # gpu or cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-berry",
   "metadata": {
    "id": "indirect-berry"
   },
   "outputs": [],
   "source": [
    "audio = apply_tts(texts=[example_text],\n",
    "                  model=model,\n",
    "                  sample_rate=sample_rate,\n",
    "                  symbols=symbols,\n",
    "                  device=device)\n",
    "\n",
    "print(example_text)\n",
    "display(Audio(audio[0], rate=sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n-IHQN_5KA_A",
   "metadata": {
    "id": "n-IHQN_5KA_A"
   },
   "source": [
    "## Enhance synthesis with logmmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ivNvVXhLKbmA",
   "metadata": {
    "id": "ivNvVXhLKbmA"
   },
   "outputs": [],
   "source": [
    "!pip install -q logmmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pLMPBH_CMAzh",
   "metadata": {
    "id": "pLMPBH_CMAzh"
   },
   "source": [
    "You can try to enhance synthesized audio with logmmse algorithm, though it could demand parameters tuning for the particular speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b048VLuzgDF",
   "metadata": {
    "id": "6b048VLuzgDF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from logmmse import logmmse\n",
    "\n",
    "enhanced = logmmse(np.array(audio[0]), sample_rate, output_file=None, initial_noise=1, window_size=160, noise_threshold=0.15)\n",
    "display(Audio(enhanced, rate=sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Pwg_AYTCmufA",
   "metadata": {
    "id": "Pwg_AYTCmufA"
   },
   "source": [
    "# Minimal Example to Run Locally "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g2t4hX0Im1U_",
   "metadata": {
    "id": "g2t4hX0Im1U_"
   },
   "source": [
    "We have received a lot of questions regarding the packaging requirements and utils from the `silero-models` repo from people trying to run models locally standalone (on their desktop for example). The project is packaged using `torch.hub` utils which basically are in the `hubconf.py` [file](https://github.com/snakers4/silero-models/blob/master/hubconf.py) and `tts_utils.py` [file](https://github.com/snakers4/silero-models/blob/master/tts_utils.py).\n",
    "\n",
    "For some reason this is very difficult to understand for some users. Also the `hubconf.py` contains some dependecies, which may not be necessarily required when running TTS for example on your desktop, i.e. `torchaudio` and `omegaconf`.\n",
    "\n",
    "The following example is a minimal standalone example for such a use-case. It has very little external dependecies (essentially just `torch`, the rest is just standard python library). It basically does the following:\n",
    "\n",
    "- Loads one of the 16 kHz models (I just chose one randomly), listed on the models.yml [file](https://github.com/snakers4/silero-models/blob/master/models.yml) locally and uses it as cache;\n",
    "- The `symbols` are taken from the same  models.yml file;\n",
    "- `apply_tts` is just one of the utils we provide in the project;\n",
    "- The rest is self-explanatory;\n",
    "\n",
    "In order to use this example, you will need to handle the resulting audios by yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_-S9KQ19mzpy",
   "metadata": {
    "id": "_-S9KQ19mzpy"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import wave\n",
    "import torch\n",
    "import contextlib\n",
    "\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "device = torch.device('cpu')\n",
    "torch.set_num_threads(4)  # safe optimal value, i.e. 2 CPU cores, does not work properly in colab\n",
    "symbols = '_~абвгдеёжзийклмнопрстуфхцчшщъыьэюя +.,!?…:;–'\n",
    "local_file = 'model.jit'\n",
    "\n",
    "\n",
    "if not os.path.isfile(local_file):\n",
    "  torch.hub.download_url_to_file('https://models.silero.ai/models/tts/ru/v1_kseniya_16000.jit',\n",
    "                                 local_file)\n",
    "\n",
    "if not os.path.isfile('tts_utils.py'):\n",
    "  torch.hub.download_url_to_file('https://raw.githubusercontent.com/snakers4/silero-models/master/tts_utils.py',\n",
    "                                 'tts_utils.py')\n",
    "  from tts_utils import apply_tts  # modify these utils and use them your project\n",
    "  \n",
    "\n",
    "model = torch.jit.load('model.jit',\n",
    "                       map_location=device)\n",
    "model.eval()\n",
    "example_batch = ['В н+едрах т+ундры в+ыдры в г+етрах т+ырят в в+ёдра +ядра к+едров.',\n",
    "                 'К+отики - +это ж+идкость!',\n",
    "                 'М+ама М+илу м+ыла с м+ылом.']\n",
    "sample_rate = 16000\n",
    "model = model.to(device)\n",
    "\n",
    "audio = apply_tts(texts=example_batch,\n",
    "                  model=model,\n",
    "                  sample_rate=sample_rate,\n",
    "                  symbols=symbols,\n",
    "                  device=device)\n",
    "\n",
    "def write_wave(path, audio, sample_rate):\n",
    "    \"\"\"Writes a .wav file.\n",
    "    Takes path, PCM audio data, and sample rate.\n",
    "    \"\"\"\n",
    "    with contextlib.closing(wave.open(path, 'wb')) as wf:\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(sample_rate)\n",
    "        wf.writeframes(audio)\n",
    "\n",
    "for i, _audio in enumerate(audio):\n",
    "  write_wave(path=f'test_{str(i).zfill(3)}.wav',\n",
    "             audio=(audio[i] * 32767).numpy().astype('int16'),\n",
    "             sample_rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_pcIug4No2Mn",
   "metadata": {
    "id": "_pcIug4No2Mn"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio, display\n",
    "display(Audio('test_000.wav', rate=16000))\n",
    "display(Audio('test_001.wav', rate=16000))\n",
    "display(Audio('test_002.wav', rate=16000))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "examples_tts.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
